{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzV9wsJ5pGhf"
   },
   "source": [
    "# <img src=\"https://img.icons8.com/bubbles/50/000000/mind-map.png\" style=\"height:50px;display:inline\"> ECE 046211 - Technion - Deep Learning\n",
    "---\n",
    "\n",
    "## Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Checking the best finetuned AST model genre estimation on any music file that is in the directory `music_dir` below.\n",
    "jamendo_music_samples is given as an example of a directory.\n",
    "The estimation algorithm:\n",
    " * Randomly sample chunks of the song.\n",
    " * Calculates the model's most likely class for each chunk.\n",
    "  * Estimates the final class as the chunks' majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "music_dir=\"jamendo_music_samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install packages that are not part of the basic virtual environment defined on the ReadMe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,Audio\n",
    "import numpy as np\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "import torch\n",
    "import os\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Upload the best finetuned AST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_id = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "model = AutoModelForAudioClassification.from_pretrained('Best_Model').to(device)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)\n",
    "sampling_rate = feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Estimate music genre using the uploaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\tech046211\\lib\\site-packages\\transformers\\models\\audio_spectrogram_transformer\\modeling_audio_spectrogram_transformer.py:187: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  context_layer = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated genre of the song Blues_Burning_You is blues with average confidence 28%\n",
      "The estimated genre of the song Classical_Clair_De_Lune is classical with average confidence 39%\n",
      "The estimated genre of the song Country_Golden_Standard is country with average confidence 57%\n",
      "The estimated genre of the song Disco_Magenta_Six is pop with average confidence 48%\n",
      "The estimated genre of the song Hiphop_Royalty is pop with average confidence 30%\n",
      "The estimated genre of the song Jazz_For_the_Fifth is jazz with average confidence 25%\n",
      "The estimated genre of the song Metal_After_Us is metal with average confidence 48%\n",
      "The estimated genre of the song Pop_Love_You_Anymore is pop with average confidence 81%\n",
      "The estimated genre of the song Reggae_The_River is pop with average confidence 44%\n"
     ]
    }
   ],
   "source": [
    "#Create a list of files in music_dir directory\n",
    "song_files=[os.path.join(music_dir,music_file) for music_file in os.listdir(music_dir)]\n",
    "for song_file in song_files:\n",
    "    #Upload a directory song to the workspace,\n",
    "    audio= Dataset.from_dict({\"audio\": [song_file]}).cast_column(\"audio\", Audio())\n",
    "    #Adapt raw audio vector to the expected model's feature extractor sampling rate.\n",
    "    audio = audio.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
    "    #Sample random chunks of the song.\n",
    "    max_duration = 30.0\n",
    "    samples=20\n",
    "    length=int(sampling_rate*max_duration)\n",
    "    if audio['audio'][0]['array'].shape[0]<length:\n",
    "        print('The music file must be at least 30 sec long.')\n",
    "    dataset=[]\n",
    "    for i in np.arange(samples):\n",
    "        end=np.random.randint(length,audio['audio'][0]['array'].shape[0])\n",
    "        dataset.append(audio['audio'][0]['array'][(end-length):end])\n",
    "    #Calculate the audio array's spectrogram and preprocess it\n",
    "    inputs = feature_extractor(dataset, sampling_rate=sampling_rate, return_tensors=\"pt\").to(device)\n",
    "    #Calculate the model's response to the sampled chunks\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    #Calculate each chunk most likely class\n",
    "    predicted_classes_ids = torch.argmax(logits, axis=1).cpu().detach().numpy()\n",
    "    #Calculate the majority class\n",
    "    majority_vote_ids=np.argmax(np.bincount(predicted_classes_ids))\n",
    "    majority_vote_class=model.config.id2label[majority_vote_ids]\n",
    "    #Calculate average chosen class probability of the chunks that predicted the majority class\n",
    "    avg_confidence=torch.mean(torch.nn.functional.softmax(logits,dim=1)[predicted_classes_ids==majority_vote_ids,majority_vote_ids]).cpu().detach().numpy()*100\n",
    "    print(f\"The estimated genre of the song {os.path.splitext(os.path.basename(song_file))[0]} is {majority_vote_class} with average confidence {avg_confidence:.0f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
